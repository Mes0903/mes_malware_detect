#ifndef ADABOOST_CLASSIFIER__
#define ADABOOST_CLASSIFIER__

/**
 * @file adaboost_classifier.h
 * @author Mes (mes900903@gmail.com) (Discord: Mes#0903)
 * @brief The declaration of Adaboost class
 * @version 0.1
 * @date 2022-11-17
 */

#include "normalize.h"
#include "Eigen/Eigen"
#include "feature_num.h"
#include "file_handler.h"

#include <tuple>
#include <vector>
#include <cmath>
#include <filesystem>
#include <iostream>
#include <fstream>
#include <sstream>


#if __cplusplus >= 202002L

/**
 * @brief Check if the weight in class can be stored.
 * @param ins The instance of the class.
 */
template <typename Model>
concept has_fit = requires(Model ins, const Eigen::MatrixXd &train_X, const Eigen::VectorXd &train_Y, const Eigen::MatrixXd &train_weight, uint32_t Iterations) {
                    ins.fit(train_X, train_Y, train_weight, Iterations);
                  };

/**
 * @param ins The instance of the class.
 */
template <typename Model>
concept has_predict = requires(Model ins, const Eigen::MatrixXd &section) {
                        {
                          ins.predict(section)
                          } -> std::same_as<Eigen::MatrixXd>;
                      };

template <typename Module>
concept valid_Model = has_fit<Module> && has_predict<Module>;

#else


/**
 * @brief Check if the class has `fit` function
 */
template <typename, typename = void>
struct has_fit : std::false_type {
};

template <typename Model>
struct has_fit<Model, std::void_t<decltype(&Model::fit)> >
    : std::is_invocable_r<void,
                          decltype(&Model::fit),
                          Model &,
                          const Eigen::MatrixXd &,
                          const Eigen::VectorXd &,
                          const Eigen::MatrixXd &,
                          int> {
};

/**
 * @brief Check if the class has `predict` function.
 */
template <typename, typename = void>
struct has_predict : std::false_type {
};

template <typename Model>
struct has_predict<Model, std::void_t<decltype(&Model::predict)> >
    : std::is_invocable_r<Eigen::MatrixXd,
                          decltype(&Model::predict),
                          Model &,
                          const Eigen::MatrixXd &> {
};

template <typename Model>
struct valid_Model : std::conjunction<has_fit<Model>, has_predict<Model> > {
};

template <typename Model>
constexpr bool valid_Model_v = valid_Model<Model>::value;

#endif


/**
 * @brief The Adaboost class, have M weak classfiers, each weak classfiers is a logistic regression classifier.
 */
#if __cplusplus >= 202002L
template <valid_Model Model>
#else
template <typename Model>
#endif
class Adaboost {
#if __cplusplus < 202002L
  static_assert(valid_Model_v<Model>, "The Model didn't fit the requires of predict function or fit function");
#endif

public:
  int M = 0;    // the number of weak classfiers
  Eigen::VectorXd alpha;    // the vector of weights for weak classfiers
  std::vector<Model> vec;    // the vector of weak classfiers

public:
  Adaboost() = default;
  Adaboost(const int M)
      : M{ M }, vec(M) { alpha = Eigen::VectorXd::Zero(M); }

  /**
   * @brief Training Adaboost.
   *
   * @param train_X The training data, which is a feature matrix.
   * @param train_Y The training label.
   */
  void fit(const Eigen::MatrixXd &train_X, const Eigen::MatrixXd &train_Y)    // training Adaboost
  {
    Eigen::VectorXd w = Eigen::VectorXd::Ones(train_X.rows());

    for (int i = 0; i < M; ++i) {
      std::cout << "\nTraining Weak Learner: " << i + 1 << '\n';
      w /= w.sum();

      vec[i].fit(train_X, train_Y, w, 1000);    // pred_Y is the label it predict, err is the error rate.
      Eigen::ArrayXXd pred_Y = vec[i].get_label(train_X);
      double err = 1 - ((pred_Y * train_Y.array()).colwise() * w.array()).sum();

      alpha(i) = std::log((1 - err) / err) + std::log(CLASS_NUM - 1);

      w = w.array() * (alpha(i) * (1 - (pred_Y * train_Y.array()).rowwise().sum())).exp();
    }
    std::cout << "\nalpha: " << alpha << '\n';
  }

  /**
   * @brief Make the prediction of the data.
   *
   * @param data The data need to be predicted, which is a feature matrix.
   * @return Eigen::VectorXd The output label vector.
   */
  Eigen::VectorXd predict(const Eigen::MatrixXd &data)    // make prediction
  {
    int R = data.rows();
    Eigen::MatrixXd C = Eigen::MatrixXd::Zero(R, CLASS_NUM);

    for (int m = 0; m < M; ++m)
      C += (alpha(m) * vec[m].get_label(data));

    Eigen::VectorXd pred_Y(R);
    for (int r = 0; r < R; ++r) {
      Eigen::MatrixXd::Index maxIndex;
      C.row(r).maxCoeff(&maxIndex);
      pred_Y(r) = maxIndex + 1;
    }

    return pred_Y;
  }

public:
  /**
   * @brief Store the weight vector of all weak learner in Adaboost.
   *
   * @param filepath For Debug using, maybe unused. The file path, where to store the weight.
   * @param outfile The file, where to store the weight, provided by the file handler.
   */
  void store_weight(std::ofstream &outfile)    // store the weights of Adaboost
  {
    outfile << M << '\n';
    for (int i = 0; i < M; ++i)
      outfile << alpha(i) << " \n"[i == M - 1];

    for (int i = 0; i < M; ++i)
      vec[i].store_weight(outfile);

    std::cout << "\nSuccessfly stored Adaboost weighting!\n";
  }

  /**
   * @brief Store the weight vector of all weak learner in Adaboost.
   *
   * @param filepath For Debug using, maybe unused. The file path, where to load the weight.
   * @param outfile The file, where to load the weight, provided by the file handler.
   */
  void load_weight(std::ifstream &infile)    // load the weights before stored.
  {
    std::string line;
    std::stringstream stream;

    getline(infile, line);
    stream << line;
    stream >> M;
    stream.str("");
    stream.clear();

    alpha = Eigen::VectorXd::Zero(M);
    getline(infile, line);
    stream << line;
    for (int i = 0; i < M; ++i)
      stream >> alpha(i);
    stream.str("");
    stream.clear();

    vec.resize(M);
    for (int i = 0; i < M; ++i) {
      vec[i].load_weight(infile);
      stream.str("");
      stream.clear();
    }
  }
};

#endif